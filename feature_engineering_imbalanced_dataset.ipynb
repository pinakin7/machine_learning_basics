{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Imbalanced Dataset Machine Learning\n",
    "This types of datasets does not heavily impact ensemble techniques or aloriths where decision trees are on count"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Class',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.model_selection import KFold,GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_class = LogisticRegression()\n",
    "grid = {'C':10.0**np.arange(-2,3),'penalty':['l1','l2']}\n",
    "cv = KFold(n_splits = 5,random_state = None,shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(log_class,grid,cv = cv,n_jobs = -1,scoring = 'f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             scoring='f1_macro')"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,train_size = 0.7)\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[85261,    32],\n",
       "       [   60,    90]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9989232587807076"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     85293\n           1       0.74      0.60      0.66       150\n\n    accuracy                           1.00     85443\n   macro avg       0.87      0.80      0.83     85443\nweighted avg       1.00      1.00      1.00     85443\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[85281    12]\n [   31   119]]\n0.9994967405170698\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(x_train,y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     85293\n           1       0.91      0.79      0.85       150\n\n    accuracy                           1.00     85443\n   macro avg       0.95      0.90      0.92     85443\nweighted avg       1.00      1.00      1.00     85443\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "source": [
    "## Under Sampling\n",
    "Reduceing points of maximum labels <br>\n",
    "This will in turn hamper the dataset and will not perform good"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from Collections import Counter"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Collections'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-54c7c2664f03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mCollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Collections'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "ns = NearMiss(0.80)\n",
    "x_train_ns,y_train_ns = ns.fit_sample(x_train,y_train)\n",
    "# print(\" The number of classes before fit {}\".format((Counter(y_train))))\n",
    "# print(\" The number of classes after fit {}\".format((Counter(y_train_ns))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[67303 17990]\n",
      " [    7   143]]\n",
      "0.7893683508303782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.79      0.88     85293\n",
      "           1       0.01      0.95      0.02       150\n",
      "\n",
      "    accuracy                           0.79     85443\n",
      "   macro avg       0.50      0.87      0.45     85443\n",
      "weighted avg       1.00      0.79      0.88     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(x_train_ns,y_train_ns)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "source": [
    "## Over Sampling\n",
    "We increase the number of data points for the label having less number of data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "os = RandomOverSampler(0.5)\n",
    "x_train_os,y_train_os = os.fit_sample(x_train,y_train)\n",
    "# print(\" The number of classes before fit {}\".format((Counter(y_train))))\n",
    "# print(\" The number of classes after fit {}\".format((Counter(y_train_os))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[85280    13]\n [   28   122]]\n0.9995201479348805\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     85293\n           1       0.90      0.81      0.86       150\n\n    accuracy                           1.00     85443\n   macro avg       0.95      0.91      0.93     85443\nweighted avg       1.00      1.00      1.00     85443\n\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(x_train_os,y_train_os)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "source": [
    "## SMOTETomek\n",
    "Includes both over and under sampling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTETomek(0.75)\n",
    "x_train_sm,y_train_sm = sm.fit_sample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(x_train_sm,y_train_sm)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "source": [
    "## Ensemble Techniques"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}